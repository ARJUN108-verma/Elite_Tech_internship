{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTGMOf+lAuZdfVoosrutmq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARJUN108-verma/Elite_Tech_internship/blob/main/Speech_Recognition_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speech Recognition System"
      ],
      "metadata": {
        "id": "zJSI-62HK5C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchaudio transformers SpeechRecognition pydub tk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lwkt-joLc1M",
        "outputId": "8994ca66-4a33-4b8f-cc73-57397df79d2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting tk\n",
            "  Downloading tk-0.1.0-py3-none-any.whl.metadata (693 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: tk, pydub, SpeechRecognition, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SpeechRecognition-3.14.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 tk-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python speech_recognition_app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycZ_DUjFLhJ0",
        "outputId": "db747199-cb26-47a4-e5d8-4156d789be7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/speech_recognition_app.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NSfHqL5QKzZ5"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox, ttk\n",
        "import speech_recognition as sr\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechRecognitionApp:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"Speech Recognition System\")\n",
        "        self.root.geometry(\"600x400\")\n",
        "\n",
        "        # Initialize models (lazy loading)\n",
        "        self.sr_recognizer = None\n",
        "        self.wav2vec_processor = None\n",
        "        self.wav2vec_model = None\n",
        "\n",
        "        self.create_widgets()\n",
        "\n",
        "    def create_widgets(self):\n",
        "        # Title\n",
        "        title_label = tk.Label(self.root, text=\"Speech-to-Text System\", font=(\"Arial\", 16, \"bold\"))\n",
        "        title_label.pack(pady=10)\n",
        "\n",
        "        # File selection\n",
        "        file_frame = tk.Frame(self.root)\n",
        "        file_frame.pack(pady=10)\n",
        "\n",
        "        self.file_path = tk.StringVar()\n",
        "        file_entry = tk.Entry(file_frame, textvariable=self.file_path, width=50)\n",
        "        file_entry.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "        browse_btn = tk.Button(file_frame, text=\"Browse\", command=self.browse_file)\n",
        "        browse_btn.pack(side=tk.LEFT)\n",
        "\n",
        "        # Method selection\n",
        "        method_frame = tk.Frame(self.root)\n",
        "        method_frame.pack(pady=10)\n",
        "\n",
        "        tk.Label(method_frame, text=\"Select Method:\").pack(side=tk.LEFT)\n",
        "\n",
        "        self.method_var = tk.StringVar(value=\"speechrecognition\")\n",
        "        sr_radio = tk.Radiobutton(\n",
        "            method_frame, text=\"SpeechRecognition (Google API)\",\n",
        "            variable=self.method_var, value=\"speechrecognition\"\n",
        "        )\n",
        "        sr_radio.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "        wav2vec_radio = tk.Radiobutton(\n",
        "            method_frame, text=\"wav2vec (Local Model)\",\n",
        "            variable=self.method_var, value=\"wav2vec\"\n",
        "        )\n",
        "        wav2vec_radio.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "        # Transcribe button\n",
        "        transcribe_btn = tk.Button(\n",
        "            self.root, text=\"Transcribe Audio\",\n",
        "            command=self.transcribe_audio, height=2, width=20\n",
        "        )\n",
        "        transcribe_btn.pack(pady=20)\n",
        "\n",
        "        # Results\n",
        "        result_frame = tk.Frame(self.root)\n",
        "        result_frame.pack(pady=10, fill=tk.BOTH, expand=True)\n",
        "\n",
        "        tk.Label(result_frame, text=\"Transcription Result:\", font=(\"Arial\", 12)).pack()\n",
        "\n",
        "        self.result_text = tk.Text(result_frame, height=10, wrap=tk.WORD)\n",
        "        self.result_text.pack(fill=tk.BOTH, expand=True, padx=10)\n",
        "\n",
        "        # Progress bar\n",
        "        self.progress = ttk.Progressbar(\n",
        "            self.root, orient=tk.HORIZONTAL,\n",
        "            length=300, mode='determinate'\n",
        "        )\n",
        "        self.progress.pack(pady=5)\n",
        "\n",
        "        # Status bar\n",
        "        self.status_var = tk.StringVar()\n",
        "        self.status_var.set(\"Ready\")\n",
        "        status_bar = tk.Label(\n",
        "            self.root, textvariable=self.status_var,\n",
        "            bd=1, relief=tk.SUNKEN, anchor=tk.W\n",
        "        )\n",
        "        status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
        "\n",
        "    def browse_file(self):\n",
        "        filetypes = [\n",
        "            (\"Audio files\", \"*.wav *.aiff *.aif *.flac *.mp3\"),\n",
        "            (\"All files\", \"*.*\")\n",
        "        ]\n",
        "        filename = filedialog.askopenfilename(\n",
        "            title=\"Select an audio file\",\n",
        "            filetypes=filetypes\n",
        "        )\n",
        "        if filename:\n",
        "            self.file_path.set(filename)\n",
        "            self.status_var.set(f\"Selected: {os.path.basename(filename)}\")\n",
        "\n",
        "    def transcribe_audio(self):\n",
        "        audio_file = self.file_path.get()\n",
        "        if not audio_file:\n",
        "            messagebox.showerror(\"Error\", \"Please select an audio file first\")\n",
        "            return\n",
        "\n",
        "        method = self.method_var.get()\n",
        "        self.result_text.delete(1.0, tk.END)\n",
        "        self.progress['value'] = 0\n",
        "        self.root.update()\n",
        "\n",
        "        try:\n",
        "            if method == \"speechrecognition\":\n",
        "                self.status_var.set(\"Transcribing using SpeechRecognition...\")\n",
        "                self.progress['value'] = 30\n",
        "                self.root.update()\n",
        "\n",
        "                result = self.transcribe_with_speechrecognition(audio_file)\n",
        "\n",
        "                self.progress['value'] = 100\n",
        "                self.status_var.set(\"Transcription complete\")\n",
        "            else:\n",
        "                self.status_var.set(\"Transcribing using wav2vec...\")\n",
        "                self.progress['value'] = 30\n",
        "                self.root.update()\n",
        "\n",
        "                result = self.transcribe_with_wav2vec(audio_file)\n",
        "\n",
        "                self.progress['value'] = 100\n",
        "                self.status_var.set(\"Transcription complete\")\n",
        "\n",
        "            self.result_text.insert(tk.END, result)\n",
        "\n",
        "        except Exception as e:\n",
        "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
        "            self.status_var.set(\"Error during transcription\")\n",
        "            self.progress['value'] = 0\n",
        "\n",
        "    def transcribe_with_speechrecognition(self, audio_file):\n",
        "        \"\"\"Transcribe using SpeechRecognition library (Google API)\"\"\"\n",
        "        if self.sr_recognizer is None:\n",
        "            self.sr_recognizer = sr.Recognizer()\n",
        "            self.status_var.set(\"Initializing SpeechRecognition...\")\n",
        "            self.root.update()\n",
        "\n",
        "        try:\n",
        "            with sr.AudioFile(audio_file) as source:\n",
        "                audio_data = self.sr_recognizer.record(source)\n",
        "\n",
        "            self.status_var.set(\"Sending to Google Speech Recognition...\")\n",
        "            self.progress['value'] = 60\n",
        "            self.root.update()\n",
        "\n",
        "            text = self.sr_recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Google Speech Recognition could not understand the audio\"\n",
        "        except sr.RequestError as e:\n",
        "            return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
        "\n",
        "    def transcribe_with_wav2vec(self, audio_file):\n",
        "        \"\"\"Transcribe using wav2vec 2.0 model\"\"\"\n",
        "        if self.wav2vec_processor is None or self.wav2vec_model is None:\n",
        "            self.status_var.set(\"Loading wav2vec model (first time may take a while)...\")\n",
        "            self.root.update()\n",
        "\n",
        "            # Use processor instead of tokenizer for better handling\n",
        "            self.wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "            self.wav2vec_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "        # Load audio file\n",
        "        waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "        # Resample to 16kHz if needed\n",
        "        if sample_rate != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "        self.status_var.set(\"Processing audio with wav2vec...\")\n",
        "        self.progress['value'] = 60\n",
        "        self.root.update()\n",
        "\n",
        "        # Preprocess and predict\n",
        "        inputs = self.wav2vec_processor(\n",
        "            waveform.squeeze().numpy(),\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self.wav2vec_model(inputs.input_values).logits\n",
        "\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        transcription = self.wav2vec_processor.batch_decode(predicted_ids)[0]\n",
        "\n",
        "        return transcription"
      ],
      "metadata": {
        "id": "G1q1udU-M6wr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Set the backend to Agg before importing pyplot"
      ],
      "metadata": {
        "id": "7jpUu9UKP1c5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def is_display_available():\n",
        "    \"\"\"Check if a display is available\"\"\"\n",
        "    return 'DISPLAY' in os.environ or sys.platform == 'darwin' or sys.platform.startswith('win')\n",
        "\n",
        "def run_headless():\n",
        "    \"\"\"Command-line interface for headless systems\"\"\"\n",
        "    print(\"Running in headless mode\")\n",
        "    # Implement your command-line functionality here\n",
        "    audio_file = input(\"Enter audio file path: \")\n",
        "    method = input(\"Choose method (1: SpeechRecognition, 2: wav2vec): \")\n",
        "\n",
        "    # Your transcription logic here\n",
        "    print(f\"Would process {audio_file} with method {method}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if is_display_available():\n",
        "        root = tk.Tk()\n",
        "        from speech_recognition_app import SpeechRecognitionApp\n",
        "        app = SpeechRecognitionApp(root)\n",
        "        root.mainloop()\n",
        "    else:\n",
        "        run_headless()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s8l7OzmP_3C",
        "outputId": "ae973548-7b21-4400-d184-a8b8f999c410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in headless mode\n"
          ]
        }
      ]
    }
  ]
}